# Project results

- **The output and correctness of each algorithm** 
  - The BFS algorithm by design finds a shortest path between two points in the dataset. We verfied the correctness of the BFS function via tests cases that confirm it does indeed pick the shortest path, and works on complicated graphs (those with cycles, for example).
  - Brandes' algorithm finds the centrality of each node in the graph. This is done by finding all of the shortest paths between all nodes and all other nodes and adding the proportions of those which contain a particular node. This involves many, many operations, and initally took nearly an hour to run. We solved this problem by doing the operations in parallel on separate threads, which drastically improved performance. We verified the accuracy of this algorithm by creating graphs with obviously central and non-central nodes, and verifying that they are as central as we expected, or are at least ordered in the way we expect.
  - The PageRank algorithm ranks all pages based on their number of outgoing links. We used a linear algebra library called Eigen to implement this. We verified the accuracy of this algorithm by creating graphs with obviously popular nodes, and verifying that they are have the rank we would expected.

- **The answer to your leading question** 
We answered this question easily via BFS, but we found that there were multiple shortest paths through the data. This begged the question: how are these paths different? This is answered using centrality and PageRank, both of which offer data about the popularity of certain nodes. We found that PageRank and Brandes indicate the higher ranked pages have higher centrality. This makes sense because the nodes with more outgoing links would have more opportunity to be part of a shortest path; the pages are typically about things that have some importance to the world, and are therefore influential on the content of the other pages. Examples include World War II and the United States.